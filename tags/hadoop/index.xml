<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hadoop on Andrew Goss · Data Engineering Manager</title>
    <link>https://andrewrgoss.com/tags/hadoop/</link>
    <description>Recent content in Hadoop on Andrew Goss · Data Engineering Manager</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>admin@andrewrgoss.com (Andrew Goss)</managingEditor>
    <webMaster>admin@andrewrgoss.com (Andrew Goss)</webMaster>
    <lastBuildDate>Mon, 16 Jan 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://andrewrgoss.com/tags/hadoop/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>HDFS DCM Matchtables V2</title>
      <link>https://andrewrgoss.com/projects/hdfs_dcm_v2_logs/</link>
      <pubDate>Mon, 16 Jan 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/projects/hdfs_dcm_v2_logs/</guid>
      <description>Projects &amp;gt;&amp;gt; HDFS DCM Matchtables V2 
Overview This is my code that pulls down daily DoubleClick Campaign Manager (DCM) log files (v2) from Google Cloud Storage (GCS) and loads them into Hadoop Distributed File System (HDFS) for use in Hive queries. The script fully replaces matchtable_v2 files with each day&amp;rsquo;s new log file on HDFS. Match tables are demoed here, but it is imperative to frequently download other log files that change more often (ex.</description>
    </item>
    
    <item>
      <title>Big Data University- Hadoop 101</title>
      <link>https://andrewrgoss.com/2017/big-data-university--hadoop-101/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/big-data-university--hadoop-101/</guid>
      <description>Course Code: BD0111EN
Course Certificate
Course Link
IBM Analytics Demo Cloud
Lesson Transcripts/Labs  My goal in taking this course was to expand upon my knowledge around Apache Hadoop, a free, open source, Java-based programming framework. Topics in this course include:
 Hadoop&amp;rsquo;s architecture and core components, such as MapReduce and the Hadoop Distributed File System (HDFS). Adding/removing nodes from Hadoop clusters, how to check available disk space on each node, and how to modify configuration parameters.</description>
    </item>
    
  </channel>
</rss>
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Engineer &amp; Software Developer in Boston</title>
    <link>https://andrewrgoss.com/</link>
    <description>Recent content on Data Engineer &amp; Software Developer in Boston</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>andrewrgoss@gmail.com (Andrew Goss)</managingEditor>
    <webMaster>andrewrgoss@gmail.com (Andrew Goss)</webMaster>
    <lastBuildDate>Fri, 29 Sep 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://andrewrgoss.com/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Budget App</title>
      <link>https://andrewrgoss.com/projects/budget_app/</link>
      <pubDate>Fri, 29 Sep 2017 00:00:00 +0000</pubDate>
      <author>andrewrgoss@gmail.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/projects/budget_app/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://andrewrgoss.com/udemy-complete-javascript/budget-app&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://andrewrgoss.com/img/projects/budget_app.png&#34; alt=&#34;Budget App&#34;&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://andrewrgoss.com/2017/udemy--complete-javascript-course/&#34;&gt;Udemy- Complete JavaScript Course&lt;/a&gt; &amp;gt;&amp;gt; &lt;b&gt;My projects&lt;/b&gt;&lt;br&gt;
&lt;a href=&#34;https://andrewrgoss.com/docs/budget-app-planning-guide.pdf&#34; target=&#34;_blank&#34;&gt;Planning Guide&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://andrewrgoss.com/udemy-complete-javascript/budget-app&#34; target=&#34;_blank&#34;&gt;View project&lt;/a&gt;
&lt;hr&gt;&lt;/p&gt;

&lt;p&gt;This project put all kinds of different JavaScript concepts from the &lt;a href=&#34;https://andrewrgoss.com/2017/udemy--complete-javascript-course/&#34;&gt;Complete JavaScript Course&lt;/a&gt; I completed into practice.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/modules_structuring.png&#34; alt=&#34;Structuring Code With Modules&#34; title=&#34;Structuring Code With Modules&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/budget_app_modules.png&#34; alt=&#34;Budget App Modules&#34; title=&#34;Budget App Modules&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/event_bubbling.png&#34; alt=&#34;Event Bubbling, Target Element, and Event Delegation&#34; title=&#34;Event Bubbling, Target Element, and Event Delegation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/event_delegation.png&#34; alt=&#34;When to Use Event Delegation&#34; title=&#34;When to Use Event Delegation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://andrewrgoss.com/udemy-complete-javascript/budget-app&#34; class=&#34;btn&#34; target=&#34;_blank&#34;&gt;View my project&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/andrewrgoss/udemy-complete-javascript/tree/gh-pages/budget-app&#34; class=&#34;btn&#34; target=&#34;_blank&#34;&gt;View my code on GitHub&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DOM Pig Game</title>
      <link>https://andrewrgoss.com/projects/dom_pig_game/</link>
      <pubDate>Fri, 29 Sep 2017 00:00:00 +0000</pubDate>
      <author>andrewrgoss@gmail.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/projects/dom_pig_game/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://andrewrgoss.com/udemy-complete-javascript/dom-pig-game&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://andrewrgoss.com/img/projects/dom_pig_game.png&#34; alt=&#34;DOM Pig Game&#34;&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://andrewrgoss.com/2017/udemy--complete-javascript-course/&#34;&gt;Udemy- Complete JavaScript Course&lt;/a&gt; &amp;gt;&amp;gt; &lt;b&gt;My projects&lt;/b&gt;&lt;br&gt;
&lt;hr&gt;&lt;/p&gt;

&lt;p&gt;Part of the &lt;a href=&#34;https://andrewrgoss.com/2017/udemy--complete-javascript-course/&#34;&gt;Complete JavaScript Course&lt;/a&gt; I completed, this project put JavaScript concepts from the section on DOM manipulation and events into practice.&lt;/p&gt;

&lt;h4 id=&#34;game-rules:229eedee5891aa94a277619cf36534ac&#34;&gt;GAME RULES:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;The game has 2 players, playing in rounds&lt;/li&gt;
&lt;li&gt;In each turn, a player rolls a dice as many times as he/she wishes. Each result get added to his ROUND score&lt;/li&gt;
&lt;li&gt;BUT, if the player rolls a 1, all his/her ROUND score gets lost. After that, it&amp;rsquo;s the next player&amp;rsquo;s turn&lt;/li&gt;
&lt;li&gt;The player can choose to &amp;lsquo;Hold&amp;rsquo;, which means that his/her ROUND score gets added to the GLOBAL score. After that, it&amp;rsquo;s the next player&amp;rsquo;s turn&lt;/li&gt;
&lt;li&gt;The first player to reach the user-set winning score wins the game&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;coding-challenges:229eedee5891aa94a277619cf36534ac&#34;&gt;CODING CHALLENGES&lt;/h4&gt;

&lt;p&gt;Change the game to follow these rules:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;A player loses his ENTIRE score when he rolls two 6 in a row. After that, it&amp;rsquo;s the next player&amp;rsquo;s turn. (Hint: Always save the previous dice roll in a separate variable)&lt;/li&gt;
&lt;li&gt;Add an input field to the HTML where players can set the winning score, so that they can change the predefined score of 100. (Hint: you can read that value with the .value property in JavaScript. This is a good oportunity to use google to figure this out :)&lt;/li&gt;
&lt;li&gt;Add another dice to the game, so that there are two dices now. The player loses his current score when one of them is a 1. (Hint: you will need CSS to position the second dice, so take a look at the CSS code for the first one.)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href=&#34;https://andrewrgoss.com/udemy-complete-javascript/dom-pig-game&#34; class=&#34;btn&#34; target=&#34;_blank&#34;&gt;View my project&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/andrewrgoss/udemy-complete-javascript/tree/gh-pages/dom-pig-game&#34; class=&#34;btn&#34; target=&#34;_blank&#34;&gt;View my code on GitHub&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Udemy- Complete JavaScript Course</title>
      <link>https://andrewrgoss.com/2017/udemy--complete-javascript-course/advanced_js_objects_functions/</link>
      <pubDate>Fri, 29 Sep 2017 00:00:00 +0000</pubDate>
      <author>andrewrgoss@gmail.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/udemy--complete-javascript-course/advanced_js_objects_functions/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/post/javascript.png&#34; alt=&#34;JavaScript&#34; title=&#34;JavaScript&#34; /&gt;&lt;br&gt;
&lt;a href=&#34;https://andrewrgoss.com/2017/udemy--complete-javascript-course/&#34;&gt;Udemy- Complete JavaScript Course&lt;/a&gt; &amp;gt;&amp;gt; &lt;b&gt;Advanced JavaScript: Objections and Functions&lt;/b&gt;
&lt;hr&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/js_objects.png&#34; alt=&#34;Objects in JavaScript&#34; title=&#34;Objects in JavaScript&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/oo_paradigm.png&#34; alt=&#34;The Object-Oriented Paradigm&#34; title=&#34;The Object-Oriented Paradigm&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/js_constructors_instances.png&#34; alt=&#34;Constructors and Instances in JavaScript&#34; title=&#34;Constructors and Instances in JavaScript&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/inheritance.png&#34; alt=&#34;Inheritance in General&#34; title=&#34;Inheritance in General&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/prototypes.png&#34; alt=&#34;Inheritance in JavaScript: Prototypes and Prototype Chains&#34; title=&#34;Inheritance in JavaScript: Prototypes and Prototype Chains&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;summary:0e899c4bc90c28bac84dfe5fb6761b11&#34;&gt;Summary&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Every JavaScript object has a &lt;b&gt;prototype property&lt;/b&gt;, which makes inheritance possible in JavaScript;&lt;/li&gt;
&lt;li&gt;The prototype property of an object is where we put methods and properties that we want &lt;b&gt;other objects to inherit&lt;/b&gt;;&lt;/li&gt;
&lt;li&gt;The Constructor&amp;rsquo;s prototype property is &lt;b&gt;NOT&lt;/b&gt; the prototype of the Constructor itself; it&amp;rsquo;s the prototype of &lt;b&gt;ALL&lt;/b&gt; instances that are created through it;&lt;/li&gt;
&lt;li&gt;When a certain method (or property) is called, the search starts in the object itself, and if it cannot be found, the search moves on to the object&amp;rsquo;s prototype. This continues until the method is found: &lt;b&gt;prototype chain.&lt;/b&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/function_objects.png&#34; alt=&#34;Functions Are Also Objects in JavaScript&#34; title=&#34;Functions Are Also Objects in JavaScript&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/closure.png&#34; alt=&#34;Closures Summary&#34; title=&#34;Closures Summary&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Udemy- Complete JavaScript Course</title>
      <link>https://andrewrgoss.com/2017/udemy--complete-javascript-course/how_js_works_behind/</link>
      <pubDate>Fri, 29 Sep 2017 00:00:00 +0000</pubDate>
      <author>andrewrgoss@gmail.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/udemy--complete-javascript-course/how_js_works_behind/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/post/javascript.png&#34; alt=&#34;JavaScript&#34; title=&#34;JavaScript&#34; /&gt;&lt;br&gt;
&lt;a href=&#34;https://andrewrgoss.com/2017/udemy--complete-javascript-course/&#34;&gt;Udemy- Complete JavaScript Course&lt;/a&gt; &amp;gt;&amp;gt; &lt;b&gt;How JavaScript Works Behind the Scenes&lt;/b&gt;
&lt;hr&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/js_code_what_happens.png&#34; alt=&#34;What Happens to JS Code?&#34; title=&#34;What Happens to JS Code?&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/execution_contexts.png&#34; alt=&#34;Execution Contexts&#34; title=&#34;Execution Contexts&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/execution_stack.png&#34; alt=&#34;Execution Stack&#34; title=&#34;Execution Stack&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/execution_context_detail.png&#34; alt=&#34;Execution Context in Detail&#34; title=&#34;Execution Context in Detail&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/variable_object.png&#34; alt=&#34;Variable Object&#34; title=&#34;Variable Object&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/js_scoping.png&#34; alt=&#34;Scoping in JavaScript&#34; title=&#34;Scoping in JavaScript&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/scope_chain.png&#34; alt=&#34;Scope Chain&#34; title=&#34;Scope Chain&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/scope_chain.png&#34; alt=&#34;Execution Stack vs. Scope Chain&#34; title=&#34;Execution Stack vs. Scope Chain&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/this_variable.png&#34; alt=&#34;&#39;This&#39; Variable&#34; title=&#34;&#39;This&#39; Variable&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Udemy- Complete JavaScript Course</title>
      <link>https://andrewrgoss.com/2017/udemy--complete-javascript-course/js_browser/</link>
      <pubDate>Fri, 29 Sep 2017 00:00:00 +0000</pubDate>
      <author>andrewrgoss@gmail.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/udemy--complete-javascript-course/js_browser/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/post/javascript.png&#34; alt=&#34;JavaScript&#34; title=&#34;JavaScript&#34; /&gt;&lt;br&gt;
&lt;a href=&#34;https://andrewrgoss.com/2017/udemy--complete-javascript-course/&#34;&gt;Udemy- Complete JavaScript Course&lt;/a&gt; &amp;gt;&amp;gt; &lt;b&gt;JavaScript in the Browser: DOM Manipulation and Events&lt;/b&gt;
&lt;hr&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/document_object_model.png&#34; alt=&#34;Document Object Model&#34; title=&#34;Document Object Model&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/dom_manipulation.png&#34; alt=&#34;DOM Manipulation&#34; title=&#34;DOM Manipulation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/what_are_events.png&#34; alt=&#34;What Are Events?&#34; title=&#34;What Are Events?&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/how_events_processed.png&#34; alt=&#34;How Events Are Processed&#34; title=&#34;How Events Are Processed&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Udemy- Complete JavaScript Course</title>
      <link>https://andrewrgoss.com/2017/udemy--complete-javascript-course/js_language_basics/</link>
      <pubDate>Fri, 29 Sep 2017 00:00:00 +0000</pubDate>
      <author>andrewrgoss@gmail.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/udemy--complete-javascript-course/js_language_basics/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/post/javascript.png&#34; alt=&#34;JavaScript&#34; title=&#34;JavaScript&#34; /&gt;&lt;br&gt;
&lt;a href=&#34;https://andrewrgoss.com/2017/udemy--complete-javascript-course/&#34;&gt;Udemy- Complete JavaScript Course&lt;/a&gt; &amp;gt;&amp;gt; &lt;b&gt;JavaScript language basics&lt;/b&gt;
&lt;hr&gt;&lt;/p&gt;

&lt;h2 id=&#34;introduction-to-javascript:107ebea9dbe8e000d775582450c35225&#34;&gt;Introduction to JavaScript&lt;/h2&gt;

&lt;h3 id=&#34;what-is-javascript:107ebea9dbe8e000d775582450c35225&#34;&gt;What is JavaScript?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;JavaScript is a lightweight, cross-platform, object-oriented computer programming language.&lt;/li&gt;
&lt;li&gt;JavaScript is one of the three core technologies of web development.&lt;/li&gt;
&lt;li&gt;JavaScript is most commonly used as part of webpages.&lt;/li&gt;
&lt;li&gt;Today, JavaScript can be used in different places:

&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Client-side: JavaScript was traditionally only used in the browser&lt;/b&gt;&lt;/li&gt;
&lt;li&gt;Server-side: Thanks to node.js, we can use JavaScript on the server as well&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;JavaScript is what made modern web development possible:

&lt;ul&gt;
&lt;li&gt;Dynamic effects and interactivity;&lt;/li&gt;
&lt;li&gt;Modern web applications that we can interact with.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;the-role-of-javascript:107ebea9dbe8e000d775582450c35225&#34;&gt;The Role of JavaScript&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/role_of_js.png&#34; alt=&#34;Role of JavaScript&#34; title=&#34;Role of JavaScript&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;variables-and-data-types:107ebea9dbe8e000d775582450c35225&#34;&gt;Variables and Data Types&lt;/h2&gt;

&lt;h3 id=&#34;primitive-javascript-data-types:107ebea9dbe8e000d775582450c35225&#34;&gt;Primitive JavaScript Data Types&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Number:&lt;/b&gt; Floating point numbers, for decimals and integers.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;String:&lt;/b&gt; Sequence of characters, used for text.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Boolean:&lt;/b&gt; Logical data type that can only be true or false.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Undefined:&lt;/b&gt; Data type of a variable which does not have a value yet.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Null:&lt;/b&gt; Also means &amp;lsquo;non-existent&amp;rsquo;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;operators:107ebea9dbe8e000d775582450c35225&#34;&gt;Operators&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Operators/Operator_Precedence&#34; target=&#34;_blank&#34;&gt;JavaScript Operator Precedence&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;boolean-logic-and-switch-statements:107ebea9dbe8e000d775582450c35225&#34;&gt;Boolean Logic and Switch Statements&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/basic_boolean_logic.png&#34; alt=&#34;Basic Boolean Logic&#34; title=&#34;Basic Boolean Logic&#34; /&gt;&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;For these sections, my code lives on Github:&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;a href=&#34;https://github.com/andrewrgoss/udemy-complete-javascript/tree/master/2-js-basics&#34; class=&#34;btn&#34; target=&#34;_blank&#34;&gt;View GitHub Repo&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Introduction to JavaScript&lt;/li&gt;
&lt;li&gt;Getting Started with JavaScript&lt;/li&gt;
&lt;li&gt;Variables and Data Types&lt;/li&gt;
&lt;li&gt;Variable Mutation and Type Coercion&lt;/li&gt;
&lt;li&gt;Operators&lt;/li&gt;
&lt;li&gt;If / else Statements&lt;/li&gt;
&lt;li&gt;Boolean Logic and Switch Statements&lt;/li&gt;
&lt;li&gt;Coding Challenge 1&lt;/li&gt;
&lt;li&gt;Coding Challenge 1: Solution&lt;/li&gt;
&lt;li&gt;Functions&lt;/li&gt;
&lt;li&gt;Statements and Expressions&lt;/li&gt;
&lt;li&gt;Arrays&lt;/li&gt;
&lt;li&gt;Objects and Properties&lt;/li&gt;
&lt;li&gt;Objects and Methods&lt;/li&gt;
&lt;li&gt;Loops and Iteration&lt;/li&gt;
&lt;li&gt;Coding Challenge 2&lt;/li&gt;
&lt;li&gt;Coding Challenge 2: Solution&lt;/li&gt;
&lt;/ol&gt;

&lt;hr&gt;

&lt;p&gt;Important Note: ES5, ES6 / ES2015 and ES2016&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/2017/udemy--complete-javascript-course/js_history.png&#34; alt=&#34;JavaScript History&#34; title=&#34;JavaScript History&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Udemy- Complete JavaScript Course</title>
      <link>https://andrewrgoss.com/2017/udemy--complete-javascript-course/</link>
      <pubDate>Fri, 29 Sep 2017 00:00:00 +0000</pubDate>
      <author>andrewrgoss@gmail.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/udemy--complete-javascript-course/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/post/javascript.png&#34; alt=&#34;JavaScript&#34; title=&#34;JavaScript&#34; /&gt;&lt;br&gt;
&lt;a href=&#34;https://www.udemy.com/certificate/UC-NWM229P1&#34; target=&#34;_blank&#34;&gt;COMPLETION CERTIFICATE&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://codingheroes.io/resources&#34; target=&#34;_blank&#34;&gt;Design and Coding Resources&lt;/a&gt;&lt;br&gt;
&lt;hr&gt;&lt;/p&gt;

&lt;p&gt;This course represented my official foray into learning JavaScript. Up to this point I&amp;rsquo;d only used it on occasion with no formal training, as my focus has been predominantly on back-end data engineering. I wanted to gain a closer perspective on full-stack development, and JavaScript is a core front-end technology for me to have as part of my stack. This course covers the following areas:&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://andrewrgoss.com/2017/udemy--complete-javascript-course/js_language_basics&#34;&gt;JavaScript language basics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://andrewrgoss.com/2017/udemy--complete-javascript-course/how_js_works_behind&#34;&gt;How JavaScript works behind the scenes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://andrewrgoss.com/2017/udemy--complete-javascript-course/js_browser&#34;&gt;JavaScript in the browser: DOM manipulation and events&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://andrewrgoss.com/2017/udemy--complete-javascript-course/advanced_js_objects_functions&#34;&gt;Advanced JavaScript: objections and functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://andrewrgoss.com/projects/budget_app&#34;&gt;Putting it all together: budget app project&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr&gt;

&lt;h5 id=&#34;my-projects:f84187bd0236cff9ef749957d6953b7f&#34;&gt;My Projects&lt;/h5&gt;

&lt;p&gt;&lt;a href=&#34;https://andrewrgoss.com/projects/dom_pig_game&#34;&gt;DOM Pig Game&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://andrewrgoss.com/projects/budget_app&#34;&gt;Budget App&lt;/a&gt;&lt;br&gt;&lt;/p&gt;

&lt;hr&gt;

&lt;h5 id=&#34;course-progress:f84187bd0236cff9ef749957d6953b7f&#34;&gt;Course Progress&lt;/h5&gt;

&lt;progress max=&#34;1.0&#34; value=&#34;1.0&#34;&gt;&lt;/progress&gt;

&lt;p&gt;100% - completed 9/29/17.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/andrewrgoss/udemy-complete-javascript&#34; class=&#34;btn&#34; target=&#34;_blank&#34;&gt;View my code on GitHub&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Complete Software Developer&#39;s Career Guide</title>
      <link>https://andrewrgoss.com/books/complete_software_dev_career_guide/</link>
      <pubDate>Fri, 15 Sep 2017 00:00:00 +0000</pubDate>
      <author>andrewrgoss@gmail.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/books/complete_software_dev_career_guide/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.amazon.com/Complete-Software-Developers-Career-Guide-ebook/dp/B073X6GNJ1&#34; target=&#34;blank&#34;&gt;&lt;img src=&#34;https://andrewrgoss.com/img/books/complete_software_dev_career_guide.jpg&#34; alt=&#34;The Complete Software Developer&#39;s Career Guide&#34; title=&#34;The Complete Software Developer&#39;s Career Guide&#34; /&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://andrewrgoss.com/books/&#34;&gt;Books&lt;/a&gt; &amp;gt;&amp;gt; &lt;b&gt;The Complete Software Developer&amp;rsquo;s Career Guide&lt;/b&gt;&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;a href=&#34;https://simpleprogrammer.com/products/careerguide/links&#34; target=&#34;_blank&#34;&gt;Book resources and links&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://membership.simpleprogrammer.com/courses/toolkit&#34; target=&#34;_blank&#34;&gt;Digital toolkit&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What&#39;s the Go Language Really Good For?</title>
      <link>https://andrewrgoss.com/2017/whats-the-go-language-really-good-for/</link>
      <pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate>
      <author>andrewrgoss@gmail.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/whats-the-go-language-really-good-for/</guid>
      <description>&lt;p&gt;&lt;sub&gt;&lt;i&gt;written by &lt;a href=&#34;http://www.infoworld.com/author/Serdar-Yegulalp&#34; target=&#34;_blank&#34;&gt;Serdar Yegulalp&lt;/a&gt;&lt;/i&gt;&lt;/sub&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.infoworld.com&#34; target=&#34;_blank&#34;&gt;InfoWorld&lt;/a&gt; examines the strengths, weaknesses, use cases, and future directions of Google&amp;rsquo;s hit programming language&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;During its eight-plus years in the wild, &lt;a href=&#34;https://golang.org&#34; target=&#34;_blank&#34;&gt;Google’s Go language&lt;/a&gt;—with version 1.8.1 out as of April 2017—has evolved from being a curiosity for alpha geeks to being the battle-tested programming language behind some of the world’s most important cloud-centric projects.&lt;/p&gt;

&lt;p&gt;Why was Go chosen by the developers of such projects as Docker and Kubernetes? What are Go’s defining characteristics, how does it differ from other programming languages, and what kinds of projects is it most suitable for building? This excellent InfoWorld article explores Go’s feature set, the optimal use cases, the language’s omissions and limitations, and where Go may be going from here.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.infoworld.com/article/3198928/development-tools/whats-the-go-language-really-good-for.html&#34; class=&#34;btn&#34; target=&#34;_blank&#34;&gt;View article&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;sub&gt;*Source: &lt;a href=&#34;http://www.infoworld.com&#34; target=_&gt;InfoWorld&lt;/a&gt;&lt;/sub&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What is a Productive Data Engineering Team?</title>
      <link>https://andrewrgoss.com/2017/what-is-a-productive-data-engineering-team/</link>
      <pubDate>Thu, 20 Apr 2017 00:00:00 +0000</pubDate>
      <author>andrewrgoss@gmail.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/what-is-a-productive-data-engineering-team/</guid>
      <description>

&lt;p&gt;&lt;sub&gt;&lt;i&gt;written by &lt;a href=&#34;https://www.oreilly.com/people/17084-jesse-anderson&#34; target=&#34;_blank&#34;&gt;Jesse Anderson&lt;/a&gt;&lt;/i&gt;&lt;/sub&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Merging the gaps between data science and engineering, and what each side can learn from the other.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In my experience working with data engineering teams, I find that most teams don’t realize they have to change their thinking about data and systems to be successful with big data. Data engineering teams need to think about how data is valuable and at what scale the data is coming in. When thinking about scale, I encourage teams to think in terms of 100 billion rows or events, processing 1PB of data, and jobs that take 10 hours to complete.&lt;/p&gt;

&lt;h2 id=&#34;imagine-processing-at-100-billion-rows:be8878b9aea0d8ff31bd44efb170191f&#34;&gt;Imagine processing at 100 billion rows&lt;/h2&gt;

&lt;p&gt;When you are processing data in real-time or batch, you need to imagine that you’re processing 100 billion rows. This affects how you think about reduces, or the equivalent of reduces, in your technology of choice. If you reduce inefficiently, or when you don’t have to, you’ll experience scaling issues.&lt;/p&gt;

&lt;h2 id=&#34;your-code-should-scale-to-1pb:be8878b9aea0d8ff31bd44efb170191f&#34;&gt;Your code should scale to 1PB&lt;/h2&gt;

&lt;p&gt;When you’re thinking about amounts of data, think in terms of 1 PB. Although you may have substantially less data stored, you’ll want to make sure your processing is planned in such a way that it can handle 1 PB. As you’re writing a program to process 100 GB, you’ll want to make sure that same code can scale to 1 PB. One common manifestation for this problem is to cache data in memory for an algorithm. While that may work at 100 GB, it probably will get an out-of-memory error at 1 PB.&lt;/p&gt;

&lt;h2 id=&#34;why-you-should-plan-for-10-hour-jobs:be8878b9aea0d8ff31bd44efb170191f&#34;&gt;Why you should plan for 10-hour jobs&lt;/h2&gt;

&lt;p&gt;When you are thinking about long-running processes, I encourage teams to think of processes requiring running for 10 hours to complete. To explain this reasoning, let’s talk about coding defensively. If you have an exception at 9.5 hours into a 10-hour job, for example, you now have two problems: to find and fix the error, and to rerun the 10-hour job.&lt;/p&gt;

&lt;p&gt;A job should be coded to check assumptions, whenever possible, and to avoid an exception from exiting a job. A common example of these issues is when a team is dealing with string-based formats, like JSON and XML, and then expecting a certain format; this could be casting a string to a number—if you don’t check that string beforehand with a regular expression, you could find yourself with an exception.&lt;/p&gt;

&lt;p&gt;Given the 10-hour job consideration, the team needs to decide what to do about data that doesn’t fit the expected input. Most frameworks won’t handle data errors by themselves—this is something the team has to solve in code. Some common options are to skip the data and move on, log the error and the data, or to die immediately. Each of these decisions is very use-case dependent. If losing data or not processing every single piece of data is the end of the world, you’ll end up having to fix any bad data, manually.&lt;/p&gt;

&lt;p&gt;Every engineering decision needs to be made through these lenses. I teach this to every team, even if their data isn’t at these levels. If a data engineering team is truly experiencing big data problems, they will hit these levels eventually.&lt;/p&gt;

&lt;h2 id=&#34;a-data-engineering-team-should-be-at-the-hub-of-the-wheel:be8878b9aea0d8ff31bd44efb170191f&#34;&gt;A data engineering team should be at the “hub of the wheel”&lt;/h2&gt;

&lt;p&gt;Sometimes I’m teaching at large enterprises and they disagree that there should be a separate data engineering team. In these situations, the enterprise is usually thinking entirely of the technical requirements. Setting a data engineering team at the hub of the wheel puts the team in a completely different light and reveals how the team can become an essential part of the business process.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://d3ansictanv2wj.cloudfront.net/image00-d628951691b15e9457f4cfe9200f20d4.jpg&#34; align=&#34;right&#34;&gt;&lt;/p&gt;

&lt;p&gt;This hub concept is often foreign or not thought of, and many organizations don’t realize their project will grow in scope. As the other parts of the organization begin to consume the data or use the data pipeline, it becomes clear the data engineering team will need help—usually to fill any skill gaps, often having to do with programming.&lt;/p&gt;

&lt;p&gt;Once a data pipeline is first released, it doesn’t stay at its initial usage; it almost always grows. There is pent-up demand for data products that the pipeline starts to facilitate. New data sets and data sources will get added. There will be new processing and consumption of data. In a complete technical free-for-all, you will end up with issues. Often, teams that lack qualified data engineers will completely misuse or misunderstand how the technologies should be used.&lt;/p&gt;

&lt;h2 id=&#34;how-to-work-with-a-data-science-team:be8878b9aea0d8ff31bd44efb170191f&#34;&gt;How to work with a data science team&lt;/h2&gt;

&lt;p&gt;Before diving into the relationship between data science and data engineering teams, I want to briefly define the roles. A data scientist is typically someone with a math and probability background, who also knows how to program. Data scientists are often familiar with big data technologies, in order to run algorithms at scale. A data science team is multidisciplinary, just like a data engineering team. The team has the variety of skills needed to prevent any gaps. It’s unusual to have a single person with all of these skills, and you’ll usually need several different people.&lt;/p&gt;

&lt;p&gt;The role of data engineer typically requires a strong background in programming and distributed systems, whereas the role of a data scientist typically requires a stronger background in math, analysis, and probabilities; of course, there is some crossover, but the two teams are more complementary than heavily overlapping.&lt;/p&gt;

&lt;h2 id=&#34;where-data-science-and-data-engineering-meet:be8878b9aea0d8ff31bd44efb170191f&#34;&gt;Where data science and data engineering meet&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://d3ansictanv2wj.cloudfront.net/image01-1ce0c458317c9db05febf41792a73973.jpg&#34;&gt;&lt;/p&gt;

&lt;p&gt;In the image above, I show how tasks are distributed between data science and data engineering teams. I could, and have, talked about this diagram for an hour. The duties are shown as more of a data science or data engineering duty by how close they are to the top or bottom of the center panel. Notice that very few duties are solely a data science or data engineering duty.&lt;/p&gt;

&lt;p&gt;There are a few points I want you to take away from this diagram. A data engineering team isn’t just there to write the code—they need to be able to analyze data, too.&lt;/p&gt;

&lt;p&gt;Likewise, data scientists aren’t just there to just make equations and throw them over the fence to the data engineering team—data scientists need to have some level of programming. If the throw-it-over-the-fence scenario becomes the perception or reality, there can be a great deal of animosity between the teams. In Figure 3, I show how there should be a high bandwidth and significant level of interaction between the two teams.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://d3ansictanv2wj.cloudfront.net/image02-94a3d7311cd4cfe3d85bd7f204066259.jpg&#34; align=&#34;right&#34;&gt;&lt;/p&gt;

&lt;h3 id=&#34;how-to-work-with-a-data-warehousing-team:be8878b9aea0d8ff31bd44efb170191f&#34;&gt;How to work with a data warehousing team&lt;/h3&gt;

&lt;p&gt;In contrast to the data science team, there is a great deal of overlap with a data warehousing team. Often, the entire reason for creating a data engineering team and moving to big data solutions is to move off of data warehousing products.&lt;/p&gt;

&lt;p&gt;Big data technologies can do everything that a data warehousing product can do and much more; however, the skillsets are very different. While a data warehousing team focuses on SQL and doesn’t program, a data engineering team focuses on SQL, programming, and other necessary skills.&lt;/p&gt;

&lt;p&gt;The data warehousing team is almost always separate from a data engineering team, yet some companies will rename their data warehousing team as a data engineering team, despite the required skillsets being very different and the levels of complexity between the two teams much greater. Elements from a data warehousing team can sometimes fill in skill gaps in a data engineering team, however—usually domain knowledge and skills in analysis. If you do decide to merge or rename your data warehousing team as a data engineering team, you will need to check for capability gaps. This is a common reason why data warehousing teams have low success rates with big data projects.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.oreilly.com/ideas/what-is-a-productive-data-engineering-team&#34; class=&#34;btn&#34; target=&#34;_blank&#34;&gt;View original article&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;sub&gt;*Source: &lt;a href=&#34;https://www.oreilly.com&#34; target=_&gt;O’Reilly&lt;/a&gt;&lt;/sub&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The 2017 Big Data Landscape</title>
      <link>https://andrewrgoss.com/2017/the-2017-big-data-landscape/</link>
      <pubDate>Wed, 05 Apr 2017 00:00:00 +0000</pubDate>
      <author>andrewrgoss@gmail.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/the-2017-big-data-landscape/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/post/big_data_landscape_2017.png&#34; alt=&#34;2017 Big Data Landscape&#34; title=&#34;2017 Big Data Landscape&#34; /&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Just released - an excellent &amp;ldquo;State of the Union&amp;rdquo; roundup of the key trends in the 2017 data ecosystem. Some high level trends and questions that are explored in this comprehensive article:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Big data + AI = the new stack. &lt;b&gt;Big data provides the pipes, and AI provides the smarts.&lt;/b&gt;&lt;/li&gt;
&lt;li&gt;Enterprise budgets - follow the money&lt;/li&gt;
&lt;li&gt;Enterprise data moving to the cloud&lt;/li&gt;
&lt;li&gt;As the big data landscape gets busier every passing year, is big data consolidation coming?&lt;/li&gt;
&lt;li&gt;The cloud wars&lt;/li&gt;
&lt;li&gt;The rise of the data team workbench. &lt;b&gt;Success in big data is based on creating an assembly line of technologies, people and processes.&lt;/b&gt;&lt;/li&gt;
&lt;li&gt;AI-powered vertical applications&lt;/li&gt;
&lt;li&gt;Bots backlash&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With the killer combination of big data and AI (hype aside), the possibilities are enormous. As core infrastructure continues to mature, and the application side, powered by AI, is bursting with activity, in 2017 the big data (and AI) ecosystem is firing on all cylinders.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://mattturck.com/bigdata2017&#34; class=&#34;btn&#34; target=&#34;_blank&#34;&gt;View the full report&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;sub&gt;*Source: &lt;a href=&#34;http://mattturck.com&#34; target=_&gt;Matt Turck&lt;/a&gt;&lt;/sub&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting Started With NSQ for Go</title>
      <link>https://andrewrgoss.com/2017/getting-started-with-nsq-for-go/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      <author>andrewrgoss@gmail.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/getting-started-with-nsq-for-go/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://nsq.io&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://andrewrgoss.com/img/post/nsq.png&#34; alt=&#34;NSQ&#34; title=&#34;NSQ&#34; /&gt;&lt;/a&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve been recently working on software application project at &lt;a href=&#34;https://www.digitaslbi.com/en-us&#34; target=&#34;_blank&#34;&gt;DigitasLBi&lt;/a&gt; where we adopted &lt;a href=&#34;http://nsq.io&#34; target=&#34;_blank&#34;&gt;NSQ&lt;/a&gt; as part of our microservices architecture. With this post I&amp;rsquo;d like to share how you can get started with NSQ by sending and receiving a simple message by writing some &lt;a href=&#34;https://golang.org&#34; target=&#34;_blank&#34;&gt;Go&lt;/a&gt; code.&lt;/p&gt;

&lt;h2 id=&#34;what-is-nsq:dda9787168a23dcd34b7e3f1e03bb799&#34;&gt;What is NSQ?&lt;/h2&gt;

&lt;p&gt;Per the official website, NSQ is a realtime distributed messaging platform designed to operate at scale, handling billions of messages per day.&lt;/p&gt;

&lt;p&gt;It promotes distributed and decentralized topologies without single points of failure, enabling fault tolerance and high availability coupled with a reliable message delivery guarantee.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://f.cloud.github.com/assets/187441/1700696/f1434dc8-6029-11e3-8a66-18ca4ea10aca.gif&#34;&gt;&lt;/img&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;nsqd&lt;/code&gt; is the daemon that receives, queues, and delivers messages to clients.&lt;/p&gt;

&lt;p&gt;With the chart above you can understand the basic premise of NSQ involves producers and consumers - within your code you create NSQ producers to push messages to NSQ that get queued up to be consumed by other programs within your application.&lt;/p&gt;

&lt;h2 id=&#34;installing-nsq-on-linux-vm:dda9787168a23dcd34b7e3f1e03bb799&#34;&gt;Installing NSQ (on Linux VM)&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ wget https://s3.amazonaws.com/bitly-downloads/nsq/nsq-1.0.0-compat.linux-amd64.go1.8.tar.gz
$ tar nsq-1.0.0-compat.linux-amd64.go1.8.tar.gz
$ sudo mv nsq-1.0.0-compat.linux-amd64.go1.8.tar.gz/bin/* /usr/local/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;launching-nsqd:dda9787168a23dcd34b7e3f1e03bb799&#34;&gt;Launching NSQD&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ nsqlookupd &amp;amp; 
$ nsqd --lookupd-tcp-address=127.0.0.1:4160 &amp;amp;
$ nsqadmin --lookupd-http-address=127.0.0.1:4161 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If done successfully you will be able to view a web UI that looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nsq.io/static/img/nsqadmin_screenshot.png&#34;&gt;&lt;/img&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;nsqadmin&lt;/code&gt; is a Web UI to view aggregated cluster stats in realtime and perform various administrative tasks.&lt;/p&gt;

&lt;h2 id=&#34;writing-your-go-program:dda9787168a23dcd34b7e3f1e03bb799&#34;&gt;Writing Your Go Program&lt;/h2&gt;

&lt;p&gt;To import the NSQ client library, use a &lt;code&gt;go get&lt;/code&gt; command:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ go get github.com/nsqio/go-nsq
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;creating-a-consumer:dda9787168a23dcd34b7e3f1e03bb799&#34;&gt;Creating a Consumer&lt;/h3&gt;

&lt;p&gt;I like creating the consumer first so I can see the handler in action after pushing a message with a producer (see next &lt;a href=&#34;#producer&#34;&gt;section&lt;/a&gt;).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
    &amp;quot;log&amp;quot;
    &amp;quot;sync&amp;quot;

    &amp;quot;github.com/nsqio/go-nsq&amp;quot;
)

func main() {
    wg := &amp;amp;sync.WaitGroup{}
    wg.Add(1)

    decodeConfig := nsq.NewConfig()
    c, err := nsq.NewConsumer(&amp;quot;My_NSQ_Topic&amp;quot;, &amp;quot;My_NSQ_Channel&amp;quot;, decodeConfig)
    if err != nil {
        log.Panic(&amp;quot;Could not create consumer&amp;quot;)
    }
    //c.MaxInFlight defaults to 1

    c.AddHandler(nsq.HandlerFunc(func(message *nsq.Message) error {
        log.Println(&amp;quot;NSQ message received:&amp;quot;)
        log.Println(string(message.Body))
        return nil
    }))

    err = c.ConnectToNSQD(&amp;quot;127.0.0.1:4150&amp;quot;)
    if err != nil {
        log.Panic(&amp;quot;Could not connect&amp;quot;)
    }
    log.Println(&amp;quot;Awaiting messages from NSQ topic \&amp;quot;My NSQ Topic\&amp;quot;...&amp;quot;)
    wg.Wait()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now run this consumer program:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ go run consume.go
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You&amp;rsquo;ll get this output:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;2017/04/05 17:33:42 INF    1 [My_NSQ_Topic/My_NSQ_Channel] (127.0.0.1:4150) connecting to nsqd
2017/04/05 17:33:42 Awaiting messages from NSQ topic &amp;quot;My NSQ Topic&amp;quot;...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This should hang there waiting to receive a NSQ message from a topic you specify. Nothing will happen just yet since there aren&amp;rsquo;t any queued up messages for this particular topic. Leave this program running in a terminal window for now. In the next step we&amp;rsquo;ll push a message to it.&lt;/p&gt;

&lt;h3 id=&#34;a-name-producer-a-creating-a-producer:dda9787168a23dcd34b7e3f1e03bb799&#34;&gt;&lt;a name=&#34;producer&#34;&gt;&lt;/a&gt;Creating a Producer&lt;/h3&gt;

&lt;p&gt;You can publish a message with a producer with some simple code like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
  &amp;quot;log&amp;quot;

  &amp;quot;github.com/nsqio/go-nsq&amp;quot;
)

func main() {
    config := nsq.NewConfig()
    p, err := nsq.NewProducer(&amp;quot;127.0.0.1:4150&amp;quot;, config)
    if err != nil {
        log.Panic(err)
    }
    err = p.Publish(&amp;quot;My_NSQ_Topic&amp;quot;, []byte(&amp;quot;sample NSQ message&amp;quot;))
    if err != nil {
        log.Panic(err)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now run this publisher program:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ go run publish.go
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this terminal window, you&amp;rsquo;ll only see this message indicating your message was published to NSQ:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;go run publish.go
2017/04/05 17:39:15 INF    1 (127.0.0.1:4150) connecting to nsqd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you look at your consumer terminal window that you left running from the previous step, you&amp;rsquo;ll now see this additional output:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;2017/04/05 17:33:42 Awaiting messages from NSQ topic &amp;quot;My NSQ Topic&amp;quot;...
2017/04/05 17:39:15 NSQ message received:
2017/04/05 17:39:15 sample NSQ message
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Congrats - you just pushed and received your first NSQ message!&lt;/p&gt;

&lt;p&gt;If you go back to your web UI console you&amp;rsquo;ll see your newly-created topic. If you drill into this topic, you can also see the channel that you consumed the message to, with the message counter at 1:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/post/nsq_topic.png&#34; alt=&#34;NSQ Topic&#34; title=&#34;NSQ Topic&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Rise of the Data Engineer</title>
      <link>https://andrewrgoss.com/2017/the-rise-of-the-data-engineer/</link>
      <pubDate>Fri, 20 Jan 2017 00:00:00 +0000</pubDate>
      <author>andrewrgoss@gmail.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/the-rise-of-the-data-engineer/</guid>
      <description>

&lt;p&gt;&lt;sub&gt;&lt;i&gt;written by &lt;a href=&#34;https://medium.freecodecamp.com/@maximebeauchemin&#34; target=&#34;_blank&#34;&gt;Maxime Beauchemin&lt;/a&gt;&lt;/i&gt;&lt;/sub&gt;&lt;/p&gt;

&lt;p&gt;I joined Facebook in 2011 as a &lt;b&gt;business intelligence engineer&lt;/b&gt;. By the time I left in 2013, I was a &lt;b&gt;data engineer&lt;/b&gt;.&lt;/p&gt;

&lt;p&gt;I wasn&amp;rsquo;t promoted or assigned to this new role. Instead, Facebook came to realize that the work we were doing transcended classic business intelligence. The role we&amp;rsquo;d created for ourselves was a new discipline entirely.&lt;/p&gt;

&lt;p&gt;My team was at forefront of this transformation. We were developing new skills, new ways of doing things, new tools, and&amp;ndash;more often than not&amp;ndash;turning our backs to traditional methods.&lt;/p&gt;

&lt;p&gt;We were pioneers. We were data engineers!&lt;/p&gt;

&lt;h2 id=&#34;data-engineering:6a9fa2d276b1eefe8e0ddcdbde3e2acf&#34;&gt;Data engineering?&lt;/h2&gt;

&lt;p&gt;&lt;b&gt;Data science&lt;/b&gt; as a discipline was going through its adolescence of self-affirming and defining itself. At the same time, &lt;b&gt;data engineering&lt;/b&gt; was the slightly younger sibling, but it was going through something similar. The data engineering discipline took cues from its sibling, while also defining itself in opposition, and finding its own identity.&lt;/p&gt;

&lt;p&gt;Like data scientists, data engineers write code. They&amp;rsquo;re highly analytical, and are interested in data visualization.&lt;/p&gt;

&lt;p&gt;Unlike data scientists&amp;ndash;and inspired by our more mature parent, &lt;b&gt;software engineering&lt;/b&gt;&amp;ndash;data engineers build tools, infrastructure, frameworks, and services. In fact, it&amp;rsquo;s arguable that data engineering is much closer to software engineering than it is to a data science.&lt;/p&gt;

&lt;p&gt;In relation to &lt;b&gt;previously existing roles&lt;/b&gt;, the data engineering field could be thought of as a superset of &lt;b&gt;business intelligence&lt;/b&gt; and &lt;b&gt;data warehousing&lt;/b&gt; that brings more elements from &lt;b&gt;software engineering&lt;/b&gt;. This discipline also integrates specialization around the operation of so called &amp;ldquo;big data&amp;rdquo; distributed systems, along with concepts around the extended Hadoop ecosystem, stream processing, and in computation at scale.&lt;/p&gt;

&lt;p&gt;In smaller companies&amp;ndash;where no &lt;b&gt;data infrastructure&lt;/b&gt; team has yet been formalized&amp;ndash;the data engineering role may also cover the workload around setting up and operating the organization&amp;rsquo;s data infrastructure. This includes tasks like setting up and operating platforms like Hadoop/Hive/HBase, Spark, and the like.&lt;/p&gt;

&lt;p&gt;In smaller environments people tend to use hosted services offered by Amazon or Databricks, or get support from companies like Cloudera or Hortonworks&amp;ndash;which essentially subcontracts the data engineering role to other companies.&lt;/p&gt;

&lt;p&gt;In larger environments, there tends to be specialization and the creation of a formal role to manage this workload, as the need for a data infrastructure team grows. In those organizations, the role of automating some of the data engineering processes falls under the hand of both the data engineering and data infrastructure teams, and it&amp;rsquo;s common for these teams to collaborate to solve higher level problems.&lt;/p&gt;

&lt;p&gt;While the engineering aspect of the role is growing in scope, other aspects of the original business engineering role are becoming secondary. Areas like crafting and maintaining portfolios of reports and dashboards are not a data engineer&amp;rsquo;s primary focus.&lt;/p&gt;

&lt;p&gt;We now have better self-service tooling where analysts, data scientist and the general &amp;ldquo;information worker&amp;rdquo; is becoming more data-savvy and can take care of data consumption autonomously.&lt;/p&gt;

&lt;h2 id=&#34;etl-is-changing:6a9fa2d276b1eefe8e0ddcdbde3e2acf&#34;&gt;ETL is changing&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ve also observed a general shift away from drag-and-drop &lt;a href=&#34;https://en.wikipedia.org/wiki/Extract,_transform,_load&#34; target=&#34;_blank&#34;&gt;ETL (Extract Transform and Load)&lt;/a&gt; tools towards a more programmatic approach. Product know-how on platforms like Informatica, IBM Datastage, Cognos, AbInitio or Microsoft SSIS isn&amp;rsquo;t common amongst modern data engineers, and being replaced by more generic software engineering skills along with understanding of programmatic or configuration driven platforms like Airflow, Oozie, Azkabhan or Luigi. It&amp;rsquo;s also fairly common for engineers to develop and manage their own job orchestrator/scheduler.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s a multitude of reasons why complex pieces of software are not developed using drag and drop tools: it&amp;rsquo;s that &lt;mark&gt;ultimately &lt;b&gt;code&lt;/b&gt; is the best abstraction there is for software&lt;/mark&gt;. While it&amp;rsquo;s beyond the scope of this article to argue on this topic, it&amp;rsquo;s easy to infer that these same reasons apply to writing ETL as it applies to any other software. Code allows for arbitrary levels of abstractions, allows for all logical operation in a familiar way, integrates well with source control, is easy to version and to collaborate on. The fact that ETL tools evolved to expose graphical interfaces seems like a detour in the history of data processing, and would certainly make for an interesting blog post of its own.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s highlight the fact that the abstractions exposed by traditional ETL tools are off-target. Sure, there&amp;rsquo;s a need to abstract the complexity of data processing, computation and storage. But I would argue that the solution is not to expose ETL primitives (like source/target, aggregations, filtering) into a drag-and-drop fashion. The abstractions needed are of a higher level.&lt;/p&gt;

&lt;p&gt;For example, an example of a needed abstraction in a modern data environment is the configuration for the experiments in an A/B testing framework: &lt;i&gt;what are all the experiment? what are the related treatments? what percentage of users should be exposed? what are the metrics that each experiment expects to affect? when is the experiment taking effect?&lt;/i&gt; In this example, we have a framework that receives precise, high level input, performs complex statistical computation and delivers computed results. We expect that adding an entry for a new experiment will result in extra computation and results being delivered. What is important to note in this example is that the input parameters of this abstraction are not the one offered by a traditional ETL tool, and that a building such an abstraction in a drag and drop interface would not be manageable.&lt;/p&gt;

&lt;p&gt;To a modern data engineer, traditional ETL tools are largely &lt;b&gt;obsolete&lt;/b&gt; because logic cannot be expressed using code. As a result, the abstractions needed cannot be expressed intuitively in those tools. Now knowing that the data engineer&amp;rsquo;s role consist largely of defining ETL, and knowing that a completely new set of tools and methodology is needed, one can argue that this forces the discipline to rebuild itself from the ground up. New stack, new tools, a new set of constraints, and in many cases, a new generation of individuals.&lt;/p&gt;

&lt;h2 id=&#34;data-modeling-is-changing:6a9fa2d276b1eefe8e0ddcdbde3e2acf&#34;&gt;Data modeling is changing&lt;/h2&gt;

&lt;p&gt;Typical data modeling techniques&amp;ndash;like the &lt;a href=&#34;https://en.wikipedia.org/wiki/Star_schema&#34; target=&#34;_blank&#34;&gt;star schema&lt;/a&gt;&amp;ndash;which defined our approach to data modeling for the analytics workloads typically associated with data warehouses, are less relevant than they once were. The traditional best practices of data warehousing are loosing ground on a shifting stack. Storage and compute is cheaper than ever, and with the advent of distributed databases that scale out linearly, the scarcer resource is engineering time.&lt;/p&gt;

&lt;p&gt;Here are some changes observed in data modeling techniques:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;further denormalization:&lt;/b&gt; maintaining &lt;a href=&#34;http://www.kimballgroup.com/1998/05/surrogate-keys&#34; target=&#34;_blank&#34;&gt;surrogate keys&lt;/a&gt; in dimensions can be tricky, and it makes fact tables less readable. The use of natural, human readable keys and dimension attributes in fact tables is becoming more common, reducing the need for costly joins that can be heavy on distributed databases. Also note that support for encoding and compression in serialization formats like Parquet or ORC, or in database engines like Vertica, address most of the performance loss that would normally be associated with denormalization. Those systems have been taught to normalize the data for storage on their own.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;b&gt;blobs:&lt;/b&gt; modern databases have a growing support for blobs through native types and functions. This opens new moves in the data modeler&amp;rsquo;s playbook, and can allow for fact tables to store multiple grains at once when needed&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;b&gt;dynamic schemas:&lt;/b&gt; since the advent of map reduce, with the growing popularity of document stores and with support for blobs in databases, it&amp;rsquo;s becoming easier to evolve database schemas without executing &lt;a href=&#34;https://en.wikipedia.org/wiki/Data_definition_language&#34; target=&#34;_blank&#34;&gt;DML&lt;/a&gt;. This makes it easier to have an iterative approach to warehousing, and removes the need to get full consensus and buy-in prior to development.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;systematically &lt;b&gt;snapshoting&lt;/b&gt; dimensions (storing a full copy of the dimension for each ETL schedule cycle, usually in distinct table partitions) as a generic way to handle &lt;a href=&#34;https://en.wikipedia.org/wiki/Slowly_changing_dimension&#34; target=&#34;_blank&#34;&gt;slowly changing dimension&lt;/a&gt; (SCD) is a simple generic approach that requires little engineering effort, and that unlike the classical approach, is easy to grasp when writing ETL and queries alike. It&amp;rsquo;s also easy and relatively cheap to denormalize the dimension&amp;rsquo;s attribute into the fact table to keep track of its value at the moment of the transaction. In retrospect, complex SCD modeling techniques are not intuitive and reduce accessibility.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;b&gt;conformance&lt;/b&gt;, as in &lt;a href=&#34;http://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/conformed-dimension&#34; target=&#34;_blank&#34;&gt;conformed dimensions&lt;/a&gt; and metrics is still extremely important in modern data environment, but with the need for data warehouses to move fast, and with more team and roles invited to contribute to this effort, it&amp;rsquo;s less imperative and more of a tradeoff. Consensus and convergence can happen as a background process in the areas where the pain point of divergence become out-of-hand.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Also, more generally, it&amp;rsquo;s arguable to say that with the commoditization of compute cycles and with more people being data-savvy then before, there&amp;rsquo;s less need to precompute and store results in the warehouse. For instance you can have complex Spark job that can compute complex analysis on-demand only, and not be scheduled to be part of the warehouse.&lt;/p&gt;

&lt;h2 id=&#34;roles-responsibilities:6a9fa2d276b1eefe8e0ddcdbde3e2acf&#34;&gt;Roles &amp;amp; responsibilities&lt;/h2&gt;

&lt;h3 id=&#34;the-data-warehouse:6a9fa2d276b1eefe8e0ddcdbde3e2acf&#34;&gt;The data warehouse&lt;/h3&gt;

&lt;p&gt;&lt;i&gt;A data warehouse is a copy of transaction data specifically structured for query and analysis.&lt;/i&gt;  &amp;ndash;Ralph Kimball&lt;/p&gt;

&lt;p&gt;&lt;i&gt;A data warehouse is a subject-oriented, integrated, time-variant and non-volatile collection of data in support of management&amp;rsquo;s decision making process.&lt;/i&gt;  &amp;ndash;Bill Inmon&lt;/p&gt;

&lt;p&gt;The data warehouse is just as relevant as it ever was, and data engineers are in charge of many aspects of its construction and operation. The data engineer&amp;rsquo;s focal point is the data warehouse and gravitates around it.&lt;/p&gt;

&lt;p&gt;The modern data warehouse is a more public institution than it was historically, welcoming data scientists, analysts, and software engineers to partake in its construction and operation. Data is simply too centric to the company&amp;rsquo;s activity to have limitation around what roles can manage its flow. While this allows scaling to match the organization&amp;rsquo;s data needs, it often results in a much more chaotic, shape-shifting, imperfect piece of infrastructure.&lt;/p&gt;

&lt;p&gt;The data engineering team will often own pockets of certified, high quality areas in the data warehouse. At Airbnb for instance, there&amp;rsquo;s a set of &amp;ldquo;core&amp;rdquo; schemas that are managed by the data engineering team, where service level agreement (SLAs) are clearly defined and measured, naming conventions are strictly followed, business metadata and documentation is of the highest quality, and the related pipeline code follows a set of well defined best practices.&lt;/p&gt;

&lt;p&gt;It also becomes the role of the data engineering team to be a &amp;ldquo;center of excellence&amp;rdquo; through the definitions of standards, best practices and certification processes for data objects. The team can evolve to partake or lead an education program sharing its core competencies to help other teams become better citizens of the data warehouse. For instance, Facebook has a &amp;ldquo;data camp&amp;rdquo; education program and Airbnb is developing a similar &amp;ldquo;Data University&amp;rdquo; program where data engineers lead session that teach people how to be proficient with data.&lt;/p&gt;

&lt;p&gt;Data engineers are also the &amp;ldquo;librarians&amp;rdquo; of the data warehouse, cataloging and organizing metadata, defining the processes by which one files or extract data from the warehouse. In a fast growing, rapidly evolving, slightly chaotic data ecosystem, metadata management and tooling become a vital component of a modern data platform.&lt;/p&gt;

&lt;h3 id=&#34;performance-tuning-and-optimization:6a9fa2d276b1eefe8e0ddcdbde3e2acf&#34;&gt;Performance tuning and optimization&lt;/h3&gt;

&lt;p&gt;With data becoming more strategic than ever, companies are growing impressive budgets for their data infrastructure. This makes it increasingly rational for data engineers to spend cycles on performance tuning and optimization of data processing and storage. Since the budgets are rarely shrinking in this area, optimization is often coming from the perspective of achieving more with the same amount of resources or trying to linearize exponential growth in resource utilization and costs.&lt;/p&gt;

&lt;p&gt;Knowing that the complexity of the data engineering stack is exploding we can assume that the complexity of optimizing such stack and processes can be just as challenging. Where it can be easy to get huge wins with little effort, diminishing returns laws typically apply.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s definitely in the interest of the data engineer to build [on] infrastructure that scales with the company, and to be resource conscious at all times.&lt;/p&gt;

&lt;h4 id=&#34;data-integration:6a9fa2d276b1eefe8e0ddcdbde3e2acf&#34;&gt;Data Integration&lt;/h4&gt;

&lt;p&gt;Data integration, the practice behind integrating businesses and systems
through the exchange of data, is as important and as challenging as its ever
been. As &lt;a href=&#34;https://en.wikipedia.org/wiki/Software_as_a_service&#34; target=&#34;_blank&#34;&gt;Software as a Service (SaaS)&lt;/a&gt; becomes the new standard way for companies to operate, the need to synchronize referential data across these systems becomes increasingly critical. Not only SaaS needs up-to-date data to function, we often want to bring the data generated on their side into our data warehouse so that it can be analyzed along the rest of our data. Sure SaaS often have their own analytics offering, but are systematically lacking the perspective that the rest of you company&amp;rsquo;s data offer, so more often than not it&amp;rsquo;s necessary to pull some of this data back.&lt;/p&gt;

&lt;p&gt;Letting these SaaS offering redefine referential data without integrating and sharing a common primary key is a disaster that should be avoided at all costs. No one wants to manually maintain two employee or customer lists in 2 different systems, and worst: having to do fuzzy matching when bringing their HR data back into their warehouse.&lt;/p&gt;

&lt;p&gt;Worst, company executive often sign deal with SaaS providers without really
considering the data integration challenges. The integration workload is systematically downplayed by vendors to facilitate their sales, and leaves data engineers stuck doing unaccounted, under appreciated work to do. Let alone the fact that typical SaaS APIs are often poorly designed, unclearly documented and &amp;ldquo;agile&amp;rdquo;: meaning that you can expect them to change without notice.&lt;/p&gt;

&lt;h3 id=&#34;services:6a9fa2d276b1eefe8e0ddcdbde3e2acf&#34;&gt;Services&lt;/h3&gt;

&lt;p&gt;Data engineers are operating at a higher level of abstraction and in some cases that means providing services and tooling to automate the type of work that data engineers, data scientists or analysts may do manually.&lt;/p&gt;

&lt;p&gt;Here are a few examples of services that data engineers and data infrastructure engineer may build and operate.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;data ingestion: services and tooling around &amp;ldquo;scraping&amp;rdquo; databases, loading logs, fetching data from external stores or APIs, &amp;hellip;&lt;/li&gt;
&lt;li&gt;metric computation: frameworks to compute and summarize engagement, growth or segmentation related metrics&lt;/li&gt;
&lt;li&gt;anomaly detection: automating data consumption to alert people anomalous events occur or when trends are changing significantly&lt;/li&gt;
&lt;li&gt;metadata management: tooling around allowing generation and consumption of metadata, making it easy to find information in and around the data warehouse&lt;/li&gt;
&lt;li&gt;experimentation: A/B testing and experimentation frameworks is often a critical piece of company&amp;rsquo;s analytics with a significant data engineering component to it&lt;/li&gt;
&lt;li&gt;instrumentation: analytics starts with logging events and attributes related to those events, data engineers have vested interests in making sure that high quality data is captured upstream&lt;/li&gt;
&lt;li&gt;sessionization: pipelines that are specialized in understand series of actions in time, allowing analysts to understand user behaviors&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Just like software engineers, data engineers should be constantly looking to automate their workloads and building abstraction that allow them to climb the complexity ladder. While the nature of the workflows that can be automated differs depending on the environment, the need to automate them is common across the board.&lt;/p&gt;

&lt;h2 id=&#34;required-skills:6a9fa2d276b1eefe8e0ddcdbde3e2acf&#34;&gt;Required Skills&lt;/h2&gt;

&lt;p&gt;&lt;b&gt;SQL mastery:&lt;/b&gt; if english is the language of business, SQL is the language of data. How successful of a business man can you be if you don&amp;rsquo;t speak good english? While generations of technologies age and fade, SQL is still standing strong as the lingua franca of data. A data engineer should be able to express any degree of complexity in SQL using techniques like &amp;ldquo;correlated subqueries&amp;rdquo; and window functions. SQL/DML/DDL primitives are simple enough that it should hold no secrets to a data engineer. Beyond the declarative nature of SQL, she/he should be able to read and understand database execution plans, and have an understanding of what all the steps are, how indices work, the different join algorithm and the distributed dimension within the plan.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Data modeling techniques:&lt;/b&gt; for a data engineer, entity-relationship modeling should be a cognitive reflex, along with a clear understanding of normalization, and have a sharp intuition around denormalization tradeoffs. The data engineer should be familiar with &lt;a href=&#34;https://en.wikipedia.org/wiki/Dimensional_modeling&#34; target=&#34;_blank&#34;&gt;dimensional modeling&lt;/a&gt; and the related concepts and lexical field.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;ETL design:&lt;/b&gt; writing efficient, resilient and &amp;ldquo;evolvable&amp;rdquo; ETL is key. This topic will be expanded upon in an upcoming blog post.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Architectural projections:&lt;/b&gt; like any professional in any given field of expertise, the data engineer needs to have a high level understanding of most of the tools, platforms, libraries and other resources at its disposal. The properties, use-cases and subtleties behind the different flavors of databases, computation engines, stream processors, message queues, workflow orchestrators, serialization formats and other related technologies. When designing solutions, she/he should be able to make good choices as to which technologies to use and have a vision as to how to make them work together.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.freecodecamp.com/the-rise-of-the-data-engineer-91be18f1e603&#34; class=&#34;btn&#34; target=&#34;_blank&#34;&gt;View original article&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;sub&gt;*Source: &lt;a href=&#34;https://medium.freecodecamp.com&#34; target=_&gt;FreeCodeCamp&lt;/a&gt;&lt;/sub&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Big Data University- Hadoop 101</title>
      <link>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      <author>andrewrgoss@gmail.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/post/hadoop.png&#34; alt=&#34;Hadoop&#34; title=&#34;Hadoop&#34; /&gt;&lt;br&gt;
&lt;a href=&#34;https://andrewrgoss.com/2017/big-data-university--hadoop-101/&#34;&gt;Big Data University- Hadoop 101&lt;/a&gt; &amp;gt;&amp;gt; &lt;b&gt;Lesson Transcripts/Labs&lt;/b&gt;&lt;br&gt;
&lt;hr&gt;
&lt;a href=&#34;https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/Unit_1_What_is_Hadoop_Part1&#34;&gt;Unit_1 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; What_is_Hadoop_Part1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/Unit_1_What_is_Hadoop_Part2&#34;&gt;Unit_1 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; What_is_Hadoop_Part2&lt;/a&gt;&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;a href=&#34;https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/Unit_2_Hadoop_Architecture_Part1&#34;&gt;Unit_2 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; Hadoop_Architecture_Part1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/Unit_2_Hadoop_Architecture_Part2&#34;&gt;Unit_2 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; Hadoop_Architecture_Part2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/Unit_2_HDFS_Command_Line&#34;&gt;Unit_2 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; HDFS_Command_Line&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/Unit_2_Hadoop_Architecture_Lab&#34;&gt;Unit_2 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; Hadoop_Architecture_Lab&lt;/a&gt;&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;a href=&#34;https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/Unit_3_Hadoop_Administration&#34;&gt;Unit_3 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; Hadoop_Administration&lt;/a&gt;&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;a href=&#34;https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/Unit_4_MapReduce&#34;&gt;Unit_4 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; MapReduce&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/Unit_4_Pig_Hive&#34;&gt;Unit_4 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; Pig_Hive&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/Unit_4_Flume_Sqoop_Oozie&#34;&gt;Unit_4 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; Flume_Sqoop_Oozie&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Big Data University- Hadoop 101</title>
      <link>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/Unit_1_What_is_Hadoop_Part1/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      <author>andrewrgoss@gmail.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/Unit_1_What_is_Hadoop_Part1/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://andrewrgoss.com/img/post/hadoop.png&#34; alt=&#34;Hadoop&#34; title=&#34;Hadoop&#34; /&gt;&lt;br&gt;
&lt;a href=&#34;https://andrewrgoss.com/2017/big-data-university--hadoop-101/&#34;&gt;Big Data University- Hadoop 101&lt;/a&gt; &amp;gt;&amp;gt; &lt;a href=&#34;https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs&#34;&gt;Lesson Transcripts/Labs&lt;/a&gt; &amp;gt;&amp;gt; &lt;b&gt;Unit_1_What_is_Hadoop_Part1&lt;/b&gt;
&lt;hr&gt;&lt;/p&gt;

&lt;iframe width=&#34;660&#34; height=&#34;371&#34; src=&#34;https://www.youtube.com/embed/-65WgvIJ5xo&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Hello everyone and welcome to Hadoop Fundamentals What is Hadoop. My name is Asma Desai and I will be covering this topic.&lt;/p&gt;

&lt;p&gt;In this video we will explain what is Hadoop and what is Big Data. We will define some Hadoop-related open source projects and give some examples of Hadoop in action. Finally we will end off with some Big Data solutions and the Cloud.&lt;/p&gt;

&lt;p&gt;Imagine this scenario: You have 1GB of data that you need to process.&lt;/p&gt;

&lt;p&gt;The data is stored in a relational database in your desktop computer which has no problem handling the load. Then your company starts growing very quickly, and that data grows to 10GB, then 100GB, and you start to reach the limits of your current desktop computer.&lt;/p&gt;

&lt;p&gt;So what do you do? You scale up by investing in a larger computer, and you are then OK for a few more months. When your data grows from 1 TB to 10TB, and then 100TB, you are again quickly approaching the limits of that computer.&lt;/p&gt;

&lt;p&gt;Moreover, you are now asked to feed your application with unstructured data coming from sources like Facebook, Twitter, RFID readers, sensors, and so on. Your management wants to derive information from both the relational data and the unstructured data and wants this information as soon as possible. What should you do? Hadoop may be the answer.&lt;/p&gt;

&lt;p&gt;What is Hadoop? Hadoop is an open source project of the Apache Foundation. It is a framework written in Java originally developed by Doug Cutting who named it after his son&amp;rsquo;s toy elephant. Hadoop uses Google&amp;rsquo;s MapReduce technology as its foundation. It is optimized to handle massive quantities of data which could be structured, unstructured or semi-structured, using commodity hardware, that is, relatively inexpensive computers.&lt;/p&gt;

&lt;p&gt;This massive parallel processing is done with great performance. However, it is a batch operation handling massive amounts of data, so the response time is not immediate. Currently, in place updates are not possible in Hadoop, but appends to existing data is supported.&lt;/p&gt;

&lt;p&gt;Now, what&amp;rsquo;s the value of a system if the information it stores or retrieves is not consistent? Hadoop replicates its data across different computers, so that if one goes down, the data is processed on one of the replicated computers. Hadoop is not suitable for OnLine Transaction Processing workloads where data is randomly accessed on structured data like a relational database.&lt;/p&gt;

&lt;p&gt;Also, Hadoop is not suitable for OnLine Analytical Processing or Decision Support System workloads where data is sequentially accessed on structured data like a relational database, to generate reports that provide business intelligence. As of Hadoop version 2.6, updates are not possible, but appends are possible. Hadoop is used for Big Data. It complements OnLine Transaction Processing and OnLine Analytical Processing. It is NOT a replacement for a relational database system.&lt;/p&gt;

&lt;p&gt;So, what is Big Data? With all the devices available today to collect data, such as RFID readers, microphones, cameras, sensors, and so on, we are seeing an explosion in data being collected worldwide. Big Data is a term used to describe large collections of data (also known as datasets) that may be unstructured, and grow so large and quickly that it is difficult to manage with a regular database or statistical tools.&lt;/p&gt;

&lt;p&gt;In terms of numbers, what are we looking at? How BIG is &amp;ldquo;big data&amp;rdquo;? Well there are more than 3.2 billion internet users, and active cell phones have surpassed 7.6 billion. There are now more in-use cell phones than there are people on the planet (7.4 billion).&lt;/p&gt;

&lt;p&gt;Twitter processes 7TB of data ever day, and 600TB of data is processed by Facebook every day. Interestingly, about 80% of this data is unstructured. With this massive amount of data, businesses need fast, reliable, deeper data insight. Therefore, Big Data solutions based on Hadoop and other analytics software are becomingmore and more relevant.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
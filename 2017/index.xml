<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2017 on Andrew Goss · Data Engineering &amp; Analytics</title>
    <link>https://andrewrgoss.com/2017/</link>
    <description>Recent content in 2017 on Andrew Goss · Data Engineering &amp; Analytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>admin@andrewrgoss.com (Andrew Goss)</managingEditor>
    <webMaster>admin@andrewrgoss.com (Andrew Goss)</webMaster>
    <lastBuildDate>Fri, 29 Sep 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://andrewrgoss.com/2017/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Udemy- Complete JavaScript Course</title>
      <link>https://andrewrgoss.com/2017/udemy--complete-javascript-course/advanced_js_objects_functions/</link>
      <pubDate>Fri, 29 Sep 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/udemy--complete-javascript-course/advanced_js_objects_functions/</guid>
      <description>Udemy- Complete JavaScript Course &amp;gt;&amp;gt; Advanced JavaScript: Objections and Functions 
Summary  Every JavaScript object has a prototype property, which makes inheritance possible in JavaScript; The prototype property of an object is where we put methods and properties that we want other objects to inherit; The Constructor&amp;rsquo;s prototype property is NOT the prototype of the Constructor itself; it&amp;rsquo;s the prototype of ALL instances that are created through it; When a certain method (or property) is called, the search starts in the object itself, and if it cannot be found, the search moves on to the object&amp;rsquo;s prototype.</description>
    </item>
    
    <item>
      <title>Udemy- Complete JavaScript Course</title>
      <link>https://andrewrgoss.com/2017/udemy--complete-javascript-course/how_js_works_behind/</link>
      <pubDate>Fri, 29 Sep 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/udemy--complete-javascript-course/how_js_works_behind/</guid>
      <description>Udemy- Complete JavaScript Course &amp;gt;&amp;gt; How JavaScript Works Behind the Scenes</description>
    </item>
    
    <item>
      <title>Udemy- Complete JavaScript Course</title>
      <link>https://andrewrgoss.com/2017/udemy--complete-javascript-course/js_browser/</link>
      <pubDate>Fri, 29 Sep 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/udemy--complete-javascript-course/js_browser/</guid>
      <description>Udemy- Complete JavaScript Course &amp;gt;&amp;gt; JavaScript in the Browser: DOM Manipulation and Events</description>
    </item>
    
    <item>
      <title>Udemy- Complete JavaScript Course</title>
      <link>https://andrewrgoss.com/2017/udemy--complete-javascript-course/js_language_basics/</link>
      <pubDate>Fri, 29 Sep 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/udemy--complete-javascript-course/js_language_basics/</guid>
      <description>Udemy- Complete JavaScript Course &amp;gt;&amp;gt; JavaScript language basics 
Introduction to JavaScript What is JavaScript?  JavaScript is a lightweight, cross-platform, object-oriented computer programming language. JavaScript is one of the three core technologies of web development. JavaScript is most commonly used as part of webpages. Today, JavaScript can be used in different places:  Client-side: JavaScript was traditionally only used in the browser Server-side: Thanks to node.js, we can use JavaScript on the server as well  JavaScript is what made modern web development possible:  Dynamic effects and interactivity; Modern web applications that we can interact with.</description>
    </item>
    
    <item>
      <title>Big Data University- Hadoop 101</title>
      <link>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/</guid>
      <description>Big Data University- Hadoop 101 &amp;gt;&amp;gt; Lesson Transcripts/Labs
 Unit_1 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; What_is_Hadoop_Part1
Unit_1 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; What_is_Hadoop_Part2
 Unit_2 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; Hadoop_Architecture_Part1
Unit_2 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; Hadoop_Architecture_Part2
Unit_2 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; HDFS_Command_Line
Unit_2 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; Hadoop_Architecture_Lab
 Unit_3 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; Hadoop_Administration
 Unit_4 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; MapReduce
Unit_4 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; Pig_Hive
Unit_4 &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; Flume_Sqoop_Oozie</description>
    </item>
    
    <item>
      <title>Big Data University- Hadoop 101</title>
      <link>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_1_what_is_hadoop_part1/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_1_what_is_hadoop_part1/</guid>
      <description>Big Data University- Hadoop 101 &amp;gt;&amp;gt; Lesson Transcripts/Labs &amp;gt;&amp;gt; Unit_1_What_is_Hadoop_Part1 
 Hello everyone and welcome to Hadoop Fundamentals What is Hadoop. My name is Asma Desai and I will be covering this topic.
In this video we will explain what is Hadoop and what is Big Data. We will define some Hadoop-related open source projects and give some examples of Hadoop in action. Finally we will end off with some Big Data solutions and the Cloud.</description>
    </item>
    
    <item>
      <title>Big Data University- Hadoop 101</title>
      <link>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_1_what_is_hadoop_part2/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_1_what_is_hadoop_part2/</guid>
      <description>Big Data University- Hadoop 101 &amp;gt;&amp;gt; Lesson Transcripts/Labs &amp;gt;&amp;gt; Unit_1_What_is_Hadoop_Part2 
 This is a list of some other open source project related to Hadoop:
 Eclipse is a popular IDE donated by IBM to the open-source community Lucene is a text search engine library written in Java Hbase is a Hadoop database Hive provides data warehousing tools to extract, transform and load (ETL) data, and query this data stored in Hadoop files Pig is a high level language that generates MapReduce code to analyze large data sets.</description>
    </item>
    
    <item>
      <title>Big Data University- Hadoop 101</title>
      <link>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_2_hdfs_command_line/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_2_hdfs_command_line/</guid>
      <description>Big Data University- Hadoop 101 &amp;gt;&amp;gt; Lesson Transcripts/Labs &amp;gt;&amp;gt; Unit_2_HDFS_Command_Line 
 Welcome to HDFS command line interface. In this presentation, I will cover the general usage of the HDFS command line interface and commands specific to HDFS. Other commands should be familiar to anyone with UNIX experience and will not be covered.
The HDFS can be manipulated through a Java API or through a command line interface. All commands for manipulating HDFS through Hadoop&amp;rsquo;s command line interface begin with hdfs, a space, and dfs.</description>
    </item>
    
    <item>
      <title>Big Data University- Hadoop 101</title>
      <link>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_2_hadoop_architecture_lab/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_2_hadoop_architecture_lab/</guid>
      <description>Big Data University- Hadoop 101 &amp;gt;&amp;gt; Lesson Transcripts/Labs &amp;gt;&amp;gt; Unit_2_Hadoop_Architecture_Lab 
 Lab exercises</description>
    </item>
    
    <item>
      <title>Big Data University- Hadoop 101</title>
      <link>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_2_hadoop_architecture_part1/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_2_hadoop_architecture_part1/</guid>
      <description>Big Data University- Hadoop 101 &amp;gt;&amp;gt; Lesson Transcripts/Labs &amp;gt;&amp;gt; Unit_2_Hadoop_Architecture_Part1 
 Welcome to the unit of Hadoop Fundamentals on Hadoop architecture. I will begin with a terminology review and then cover the major components of Hadoop. We will see what types of nodes can exist in a Hadoop cluster and talk about how Hadoop uses replication to lessen data loss. Finally I will explain an important feature of Hadoop called &amp;ldquo;rack awareness&amp;rdquo; or &amp;ldquo;network topology awareness&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>Big Data University- Hadoop 101</title>
      <link>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_2_hadoop_architecture_part2/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_2_hadoop_architecture_part2/</guid>
      <description>Big Data University- Hadoop 101 &amp;gt;&amp;gt; Lesson Transcripts/Labs &amp;gt;&amp;gt; Unit_2_Hadoop_Architecture_Part2 
 Hadoop 2.2 brought about architectural changes to MapReduce. As Hadoop has matured, people have found that it can be used for more than running MapReduce jobs. But to keep each new framework from having its own resource manager and scheduler, that would compete with the other framework resource managers and schedulers, it was decided to have the recourse manager and schedulers to be external to any framework.</description>
    </item>
    
    <item>
      <title>Big Data University- Hadoop 101</title>
      <link>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_3_hadoop_administration/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_3_hadoop_administration/</guid>
      <description>Big Data University- Hadoop 101 &amp;gt;&amp;gt; Lesson Transcripts/Labs &amp;gt;&amp;gt; Unit_3_Hadoop_Administration 
 Welcome to the unit on Hadoop Administration. The agenda covers adding nodes to a cluster, verifying the health of a cluster, and stopping / starting components. Then the unit covers configuring Hadoop and setting up rack topology. Let&amp;rsquo;s begin with adding and removing nodes from a cluster.
Adding nodes can be performed from the Ambari Console. To do so requires either the ip address or hostname of the node to be added.</description>
    </item>
    
    <item>
      <title>Big Data University- Hadoop 101</title>
      <link>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_4_flume_sqoop_oozie/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_4_flume_sqoop_oozie/</guid>
      <description>Big Data University- Hadoop 101 &amp;gt;&amp;gt; Lesson Transcripts/Labs &amp;gt;&amp;gt; Unit_4_Flume_Sqoop_Oozie 
 Now let us look at moving data into Hadoop. We will begin by looking at Flume&amp;rsquo;s architecture, then examining the three modes it can run in followed by a look at the event data model. Flume is an open source software program developed by Cloudera that acts as a service for aggregating and moving large amounts of data around a Hadoop cluster as the data is produced or shortly thereafter.</description>
    </item>
    
    <item>
      <title>Big Data University- Hadoop 101</title>
      <link>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_4_mapreduce/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_4_mapreduce/</guid>
      <description>Big Data University- Hadoop 101 &amp;gt;&amp;gt; Lesson Transcripts/Labs &amp;gt;&amp;gt; Unit_4_MapReduce 
 Welcome to Hadoop Fundamentals, Hadoop Components. In this unit I will discuss the MapReduce Philosophy, describe the usage of Pig and Hive, talk about how to get data into Hadoop through the use of Flume and Sqoop and finally describe how to schedule and control job execution using Oozie.
First I need to set the boundaries for this unit.</description>
    </item>
    
    <item>
      <title>Big Data University- Hadoop 101</title>
      <link>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_4_pig_hive/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      <author>admin@andrewrgoss.com (Andrew Goss)</author>
      <guid>https://andrewrgoss.com/2017/big-data-university--hadoop-101/lesson_transcripts_labs/unit_4_pig_hive/</guid>
      <description>Big Data University- Hadoop 101 &amp;gt;&amp;gt; Lesson Transcripts/Labs &amp;gt;&amp;gt; Unit_4_Pig_Hive 
 Pig and Hive have much in common. They all translate high-level languages into MapReduce jobs so that the programmer can work at a higher level than he or she would when writing MapReduce jobs in Java or other lower-level languages supported by Hadoop using Hadoop streaming. The high level languages offered by Pig and Hive let you write programs that are much smaller than the equivalent Java code.</description>
    </item>
    
  </channel>
</rss>